"""
Mask R-CNN
The main Mask R-CNN model implemenetation.

Copyright (c) 2017 Matterport, Inc.
Licensed under the MIT License (see LICENSE for details)
Written by Waleed Abdulla
"""

import os
import sys
import glob
import random
import calc
import datetime
import itertools
import json
import re
import logging
from collections import OrderedDict
import numpy as np
import scipy.misc
import tensorflow as tf
import keras
import keras.backend as K
import keras.layers as KL
import keras.initializers as KI
import keras.engine as KE
import keras.models as KM

import utils
## IMPORT ALL SINGLE FUNCTIONS OF EACH MODEL MODULE
from mask_rcnn.model.data_formatting import compose_image_meta
from mask_rcnn.model.data_formatting import parse_image_meta
from mask_rcnn.model.data_formatting import parse_image_meta_graph
from mask_rcnn.model.data_formatting import mold_image
from mask_rcnn.model.data_formatting import unmold_image

from mask_rcnn.model.data_generator import load_image_gt
from mask_rcnn.model.data_generator import build_detection_targets
from mask_rcnn.model.data_generator import build_rpn_targets
from mask_rcnn.model.data_generator import generate_random_rois
from mask_rcnn.model.data_generator import data_generator

from mask_rcnn.model.graph_FeaturePyramid import fpn_classifier_graph
from mask_rcnn.model.graph_FeaturePyramid import build_fpn_mask_graph

from mask_rcnn.model.graph_regionProposal import rpn_graph
from mask_rcnn.model.graph_regionProposal import build_rpn_model

from mask_rcnn.model.graph_resnet import identity_block
from mask_rcnn.model.graph_resnet import conv_block
from mask_rcnn.model.graph_resnet import resnet_graph

from mask_rcnn.model.graph_mask_rcnn import MaskRCNN

from mask_rcnn.model.layer_detection import clip_to_window
from mask_rcnn.model.layer_detection import refine_detections
from mask_rcnn.model.layer_detection import DetectionLayer

from mask_rcnn.model.layer_detectionTarget import overlaps_graph
from mask_rcnn.model.layer_detectionTarget import detection_targets_graph
from mask_rcnn.model.layer_detectionTarget import DetectionTargetLayer

from mask_rcnn.model.layer_proposal import apply_box_deltas_graph
from mask_rcnn.model.layer_proposal import clip_boxes_graph
from mask_rcnn.model.layer_proposal import ProposalLayer

from mask_rcnn.model.layer_ROIAlign import log2_graph
from mask_rcnn.model.layer_ROIAlign import PyramidROIAlign

from mask_rcnn.model.losses import smooth_l1_loss
from mask_rcnn.model.losses import rpn_class_loss_graph
from mask_rcnn.model.losses import rpn_bbox_loss_graph
from mask_rcnn.model.losses import mrcnn_class_loss_graph
from mask_rcnn.model.losses import mrcnn_bbox_loss_graph
from mask_rcnn.model.losses import mrcnn_mask_loss_graph

from mask_rcnn.model.misc import trim_zeros_graph
from mask_rcnn.model.misc import batch_pack_graph

from mask_rcnn.model.util import log
from mask_rcnn.model.util import BatchNorm
# END IMPORT SINGLE FUNCTIONS FROM MODEL MODULES

# for importing model modules (obsolete)
# from mask_rcnn.model import data_formatting
# from mask_rcnn.model import data_generator
# from mask_rcnn.model import graph_FeaturePyramid
# from mask_rcnn.model import graph_regionProposal
# from mask_rcnn.model import graph_resnet
# from mask_rcnn.model import graph_mask_rcnn
# from mask_rcnn.model import layer_detection
# from mask_rcnn.model import layer_detectionTarget
# from mask_rcnn.model import layer_proposal
# from mask_rcnn.model import layer_ROIAlign
# from mask_rcnn.model import losses
# from mask_rcnn.model import misc
# from mask_rcnn.model import util


# Requires TensorFlow 1.3+ and Keras 2.0.8+.
from distutils.version import LooseVersion
assert LooseVersion(tf.__version__) >= LooseVersion("1.3")
assert LooseVersion(keras.__version__) >= LooseVersion('2.0.8')

############################################################
#  Region Proposal Network (RPN)
############################################################

def rpn_graph(feature_map, anchors_per_location, anchor_stride):
    """Builds the computation graph of Region Proposal Network.

    feature_map: backbone features [batch, height, width, depth]
    anchors_per_location: number of anchors per pixel in the feature map
    anchor_stride: Controls the density of anchors. Typically 1 (anchors for
                   every pixel in the feature map), or 2 (every other pixel).

    Returns:
        rpn_logits: [batch, H, W, 2] Anchor classifier logits (before softmax)
        rpn_probs: [batch, W, W, 2] Anchor classifier probabilities.
        rpn_bbox: [batch, H, W, (dy, dx, log(dh), log(dw))] Deltas to be
                  applied to anchors.
    """
    # TODO: check if stride of 2 causes alignment issues if the featuremap
    #       is not even.
    # Shared convolutional base of the RPN
    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',
                       strides=anchor_stride,
                       name='rpn_conv_shared')(feature_map)

    # Anchor Score. [batch, height, width, anchors per location * 2].
    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',
                  activation='linear', name='rpn_class_raw')(shared)

    # Reshape to [batch, anchors, 2]
    rpn_class_logits = KL.Lambda(
        lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x)

    # Softmax on last dimension of BG/FG.
    rpn_probs = KL.Activation(
        "softmax", name="rpn_class_xxx")(rpn_class_logits)

    # Bounding box refinement. [batch, H, W, anchors per location, depth]
    # where depth is [x, y, log(w), log(h)]
    x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding="valid",
                  activation='linear', name='rpn_bbox_pred')(shared)

    # Reshape to [batch, anchors, 4]
    rpn_bbox = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x)

    return [rpn_class_logits, rpn_probs, rpn_bbox]


def build_rpn_model(anchor_stride, anchors_per_location, depth):
    """Builds a Keras model of the Region Proposal Network.
    It wraps the RPN graph so it can be used multiple times with shared
    weights.

    anchors_per_location: number of anchors per pixel in the feature map
    anchor_stride: Controls the density of anchors. Typically 1 (anchors for
                   every pixel in the feature map), or 2 (every other pixel).
    depth: Depth of the backbone feature map.

    Returns a Keras Model object. The model outputs, when called, are:
    rpn_logits: [batch, H, W, 2] Anchor classifier logits (before softmax)
    rpn_probs: [batch, W, W, 2] Anchor classifier probabilities.
    rpn_bbox: [batch, H, W, (dy, dx, log(dh), log(dw))] Deltas to be
                applied to anchors.
    """
    input_feature_map = KL.Input(shape=[None, None, depth],
                                 name="input_rpn_feature_map")
    outputs = rpn_graph(input_feature_map, anchors_per_location, anchor_stride)
    return KM.Model([input_feature_map], outputs, name="rpn_model")

