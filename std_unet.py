# UNET TRAINING AND TESTING
# =========================
#
# Python (commandline) script for training and/or testing a Unet.
#
# Author: Hannes Horneber
# Date: 2018-03-18

from __future__ import division, print_function

import os
import sys
import argparse
import configparser
import shutil
import time
import datetime
import matplotlib;
matplotlib.use('Agg')  # set this before any other module makes use of matplotlib (and sets it)

import numpy as np
import scipy.io
from timeit import default_timer as timer
from collections import OrderedDict

# check how long tensorflow import takes
print('Importing tensorflow ...')
t_start = timer()
import tensorflow as tf
print('Elapsed time: %.4f s' % (timer() - t_start))
from tensorflow.python import debug as tf_debug
from tensorflow import contrib as tc

import logging
from util import config_util
from util import img_util
from util import calc
from util import logs
from util import filesys
from util import tf_helpers
# from unet import model
from unet import model_dev as model
from unet import data_layers
from unet import uncertainty
from util.tfutils import SimpleTrainer

# ######################################################################################################################
# LOGGING OPTIONS
# ---------------
# output log to output folder [script-location]/log
logs.initDebugLogger(os.path.join(sys.path[0], "log"), script_name="std_unet")
# output error log to output folder [script-location]/log
logs.initErrorLogger(os.path.join(sys.path[0], "log"), script_name="std_unet-err")
# console logger - depending on your settings this might not be necessary and produce doubled output
logs.initConsoleLogger()

# ######################################################################################################################
# COMMANDLINE ARGUMENTS PARSER
# ----------------------------
# all required flags are set to False to be able to run this script from environments w/o commandline options
# change defaults or override commandline args below to change what you are providing

parser = argparse.ArgumentParser(description='UNet Training and Testing')
# TRAINING & TESTING arguments
parser.add_argument('--mode', '-m', metavar='mode', required=False,
                    help="CL parameter to activate phases ['train' or 'test'] " +
                         "or modes ['tfdbg': TensorFlow CLI debugger, 'debug': Additonal debug code]. " +
                         "To activate multiple phases, just concatenate strings in arbitrary order, " +
                         "e.g. ('traintest' or 'testtrain' or 'debugtrain').",
                    default=None)
parser.add_argument('--config', '-c', metavar='config', required=False,
                    help="The location of the config file. Defaults to config.ini in train_dir (if existent)" +
                         " or otherwise config.ini in this script's directory.",
                    default=None)
parser.add_argument('--checkpoint', '-ckp', metavar='checkpoint', required=False,
                    help='Provide a model checkpoint file, otherwise searching for last one in train_dir/checkpoints.' +
                         'For training: Trains from scratch if no checkpoint is found.' +
                         'For testing: Breaks if no checkpoint is found (model cannot initialize).',
                    default=None)
parser.add_argument('--code_copy_dir', '-cc', metavar='code_copy_dir', required=False,
                    help='If specified, script and model .py will be copied to this dir. Default: train_dir.',
                    default='train_dir')

#   for output of training / input of testing:
#       either output_dir/name ...
parser.add_argument('--name', '-n', metavar='train_name', required=False,
                    help='The training session name (if not specified using time only)',
                    default=time.strftime("%Y-%m-%d_%H%M"))
parser.add_argument('--output_dir', '-o', metavar='output_dir', required=False,
                    help='Model and training files are written to train_dir=\"output_dir/name/\".',
                    default='/home/hornebeh/proj_tf_unet/output/')
#       ... or a full train_dir path:
parser.add_argument('--train_dir', '-t', metavar='train_dir', required=False,
                    help='Directory where models (checkpoints) are stored during training and loaded for testing. ' +
                         'Usually generated as train_dir=\"output_dir/name/\".' +
                         'Pass this if you don\'t want to specify name and dir separately ' +
                         '(e.g. testing an already trained network) - or if for some reason you want to use a ' +
                         'different directory than the one that is generated by default for training ' +
                         '(this overrides output_dir and name).',
                    default=None)

# TRAINING ARGUMENTS
parser.add_argument('--continue_training', '-ct', metavar='continue_training', required=False,
                    help='If True, will continue training from latest checkpoint. ' +
                         'Otherwise train_dir is recreated (avoids overwriting by appending _N).',
                    default=False)

# TESTING ARGUMENTS
parser.add_argument('--test_dir', '-p', metavar='test_dir', required=False,
                    help='Prediction is written to \"test_dir/\". ' +
                         'If not specified using prediction subfolder in train_dir.',
                    default=None)

args = parser.parse_args()

# ######################################################################################################################
# SCRIPT ARGS / OVERRIDE ARGS
# ---------------------------
def _________________________OPTIONS___________________________(): pass  # dummy function for PyCharm IDE
# Most options are defined and loaded via a config.ini

# -> Override CLI arguments (for convenience when running from IDE)
PROJECT_DIR = '/misc/lmbraid19/hornebeh/std/projects/remote_deployment/win_tf_unet/'

# args.output_dir = '/home/hornebeh/proj_tf_unet/output/'
# args.output_dir = '/home/hornebeh/proj_tf_unet/output_scr/'

# args.name = 'overwrite'
# args.name = 'unet_' + time.strftime("%Y-%m-%d_%H%M") + '_sh-aug-kp09-60k'
# generate name for new training by reading config
args.name = 'unet_' + time.strftime("%d_%H%M") \
            + '_' + config_util.keystr_from_config(args.config, section='TRAIN')

# args.train_dir = PROJECT_DIR + 'output/' + 'unet_2018-04-05_1409_debug_batch_norm'
# args.train_dir = PROJECT_DIR + 'output_scr/' + 'unet_2018-03-25_2021_augment_saver'

# args.checkpoint = PROJECT_DIR + 'output/' + 'unet_2018-04-05_1425_debug_no_batch_norm/checkpoints/snapshot-4000'
# args.checkpoint = PROJECT_DIR + 'output_scr/' + unet_2018-03-22_2021_augment/checkpoints/snapshot-34000"

logging.info('#====================================================================#')
logging.info('#' + ' '*((70-2-len(args.name))//2) + args.name + ' '*((70-1-len(args.name))//2) + '#')
logging.info('#====================================================================#')

# ######################################################################################################################
# SETUP VARS AND DIRS
# -------------------

# if opts.debug: logging.debug(str(os.environ))    # log environment (to check whether CUDA paths are set correctly etc.)
logging.debug('os.uname: %s' % (str(os.uname())))  # log uname to check which node code is running on

args.train_dir, args.continue_training = filesys.find_or_create_train_dir(
    args.name, args.output_dir, args.train_dir, args.continue_training)

args.code_copy_dir = filesys.find_or_create_code_copy_dir(
    __file__, args.code_copy_dir, args.train_dir)

# ######################################################################################################################

class config_extended(config_util.config_decorator):
    """
    Wrapper class for control flow options and default config options.
    It extends
    """

    def __init__(self, config, default='DEFAULT'):
        self.config_prox = config[default]

    debug = True if args.mode is None else ('debug' in args.mode)
    tfdbg = False if args.mode is None else ('tfdbg' in args.mode)
    prep = False if args.mode is None else ('prep' in args.mode)
    # ---------> Training
    train = True if args.mode is None else ('train' in args.mode)  # script will train
    if (train): train_dir = args.train_dir
    # ---------> Testing
    test = True if args.mode is None else ('test' in args.mode)  # script will do testing
    if (test): test_dir = args.test_dir

    tf_config = tf.ConfigProto(log_device_placement=False)
    if 'dacky' in os.uname()[1]:
        logging.info('Dacky: Running with memory usage limits')
        # change tf_config for dacky to use only 1 GPU
        tf_config.gpu_options.per_process_gpu_memory_fraction = 0.6
        os.environ["CUDA_VISIBLE_DEVICES"] = "1"
    else:
        # change tf_config for lmb_cluster so that GPU is visible and utilized
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"


# initialize options from config file
config = configparser.ConfigParser()
config.read(filesys.find_or_create_config_path(args.train_dir, config_path=args.config))

opts = config_extended(config, default='DEFAULT')
opts_test = config_util.config_decorator(config['TEST'])
opts_train = config_util.config_decorator(config['TRAIN'])
try: opts_val = config_util.config_decorator(config['VAL'])
except KeyError: opts_val = None

# output opts to console
print(config_util.opts_to_str(opts, 'DEFAULT'))
if opts.train:
    print(config_util.opts_to_str(opts_train, 'TRAIN'))
if opts.test:
    print(config_util.opts_to_str(opts_train, 'TEST'))
# ######################################################################################################################
# TRAINING
# --------
def __________________________TRAIN______________________________(): pass  # dummy function for PyCharm IDE


# core code for training
def train_core(sess, net):
    logging.info('#-----------------------------------------------#')
    logging.info('#               Starting Training               #')
    logging.info('#-----------------------------------------------#')

    # create a tfutils.SimpleTrainer that handles the mainloop and manages checkpoints
    trainer = SimpleTrainer(session=sess, train_dir=args.train_dir)
    # load model for continued training (if None provided, searches in train_dir, if not found doesn't load)
    chkpt_loaded = trainer.load_checkpoint(args.checkpoint)
    # init variables if no checkpoint was loaded
    if not chkpt_loaded: sess.run(tf.group(tf.global_variables_initializer()))
    logging.info("Loaded variables from checkpoint" if chkpt_loaded else "Randomly initialized variables")

    # set train_op and summaries
    logging.info('Setup training op (set loss, global_step and tensorboard summaries)')
    train_op, global_step, loss, merged_summary = \
        net.create_train_op(opts_train, img_summary=True)

    # in case any tf vars are not initialized. Specifically needed for ADAM if ADAM variables aren't stored/loaded
    tf_helpers.initialize_uninitialized(sess, vars=tf.global_variables())
    # initializing local variables might be needed for some metrics
    tf_helpers.initialize_uninitialized(sess, vars=tf.local_variables())

    # setup saver list
    saver_list = tf.global_variables()  # tf.trainable_variables() might not contain all relevant variables
    saver_list.append(global_step)  # for easy output: import pprint; pprint.pprint(saver_list)

    # create and setup validation ops
    val_ops = net.setup_val_ops()
    logging.info('Setup validation ops: ' + str(val_ops))

    trainer.mainloop(
        max_iter=opts_train.max_iter,
        saver_interval=opts_train.saver_interval,
        saver_var_list=saver_list,
        train_ops=([train_op]),
        display_str_ops=[('Loss', loss)],
        display_interval=1,
        runstats_interval=100,
        trace_interval=100,
        summary_int_ops=[(1, merged_summary)],
        test_int_fn=val_ops
    )


# core code for training with debug store
def train_debug(sess, net):
    logging.info('#-----------------------------------------------#')
    logging.info('#               Starting Training (debug)       #')
    logging.info('#-----------------------------------------------#')

    # create a tfutils.SimpleTrainer that handles the mainloop and manages checkpoints
    trainer = SimpleTrainer(session=sess, train_dir=args.train_dir)

    logging.info('Initializing or loading variables')
    # TODO Debug saving method
    saver = tf.train.Saver()
    save_dir = args.train_dir + os.sep + "save"
    save_path = save_dir + os.sep + "model.ckpt"
    if os.path.exists(save_path):
        try:
            logging.info("Attempt restore safe debug model from: %s" % save_dir)
            saver.restore(sess, save_dir + os.sep + "model.ckpt")
            chkpt_loaded = True
            logging.info(" -- Restored --")
        except:
            logging.info("Attempt restore with SimpleTrainer load from: %s" % args.checkpoint)
            # load model for continued training (if None provided, searches in train_dir, if not found doesn't load)
            chkpt_loaded = trainer.load_checkpoint(args.checkpoint)
            # init variables if no checkpoint was loaded
    else:
        chkpt_loaded = False

    if not chkpt_loaded: sess.run(tf.group(tf.global_variables_initializer()))
    logging.info("Loaded variables from checkpoint" if chkpt_loaded else "Randomly initialized variables")

    # set train_op and summaries
    logging.info('Create Training step (set loss, summary and global_step)')
    train_op, global_step, loss, merged_summary = \
        net.create_train_op(opts_train.init_learning_rate, opts_train.optimizer,
                            img_summary=True, metrics=True)

    # in case any tf vars are not initialized. Specifically needed for ADAM if ADAM variables aren't stored/loaded
    tf_helpers.initialize_uninitialized(sess, vars=tf.global_variables())
    # initializing local variables might be needed for some metrics
    tf_helpers.initialize_uninitialized(sess, vars=tf.local_variables())

    # setup saver list
    saver_list = tf.global_variables()  # tf.trainable_variables() might not contain all relevant variables
    saver_list.append(global_step)  # for easy output: import pprint; pprint.pprint(saver_list)

    # create and setup validation ops
    val_ops = net.setup_val_ops()

    trainer.mainloop(
        max_iter=opts_train.max_iter,
        saver_interval=opts_train.saver_interval,
        saver_var_list=saver_list,
        train_ops=([train_op]),
        display_str_ops=[('Loss', loss)],
        display_interval=1,
        runstats_interval=100,
        trace_interval=100,
        summary_int_ops=[(1, merged_summary)],
        test_int_fn=val_ops
    )

    # TODO Debug saving method
    if not os.path.exists(save_dir):
        os.mkdir(save_dir)
    saver.save(sess, save_path)
    logging.info("Safe debug model saved: %s" % save_path)


def TRAIN(): pass # dummy function for PyCharm IDE
if opts.train:
    logging.info('####################################################################')
    logging.info('#                            TRAINING                              #')
    logging.info('####################################################################')

    # set checkpoint path from opts if set in there not given per command line (CL) argument
    if args.checkpoint is None and opts_train.global_step is not None:
        args.checkpoint = args.train_dir + '/checkpoints/snapshot-' + opts_train.global_step

    # create session (tfdbg works only in command line)
    with tf_debug.LocalCLIDebugWrapperSession(tf.Session(config=opts.tf_config)) if opts.tfdbg \
            else tf.Session(config=opts.tf_config) as sess:

        # create network graph with data layer
        net = model.UNet(is_training=True, keep_prob=opts_train.keep_prob,
                         n_contracting_blocks=opts.n_contracting_blocks,
                         n_start_features=opts.n_start_features,
                         norm_fn=opts.norm_fn, normalizer_params=opts.norm_fn_params,
                         aleatoric_sample_n=opts.aleatoric_sample_n,
                         copy_script_dir=args.code_copy_dir, debug=opts.debug,
                         opts_main=opts_train, opts_val=opts_val,
                         sess=sess, train_dir=args.train_dir
                         )


        if opts.prep:
            logging.info('#-X-------------- SETUP COMPLETE ---------------#')
            sys.exit()

        if not opts.debug:
            train_core(sess, net)
        else:
            train_debug(sess, net)
            # train_own(sess, net)

    logging.info('#-X---------------------------------------------#')
    logging.info('#                Finish Training                #')
    logging.info('#-----------------------------------------------#')


# ######################################################################################################################
# TESTING
# -------
def ___________________________TEST______________________________(): pass  # dummy function for PyCharm IDE

# reset graph so that variables don't have to be reused (they will be restored from checkpoint)
if opts.train: tf.reset_default_graph()

def test_debug(sess, net_test):
    logging.info('#-----------------------------------------------#')
    logging.info('#               Starting Testing (debug)        #')
    logging.info('#-----------------------------------------------#')

    # load model for testing (if None provided, searches in train_dir, if not found doesn't load)
    trainer = SimpleTrainer(session=sess, train_dir=args.train_dir)
    chkpt_loaded = trainer.load_checkpoint(args.checkpoint)
    # init variables if no checkpoint was loaded
    if not chkpt_loaded: sess.run(tf.group(tf.global_variables_initializer()))
    logging.info("Loaded variables from checkpoint" if chkpt_loaded else "Randomly initialized (!) variables")

    # add softmax op
    net_batch_softmax = tf.nn.softmax(net_test.output_mask)
    # add uncertainty op if supported (network trained with aleatoric loss)
    if opts_test.aleatoric_sample_n is not None and opts_test.aleatoric_sample_n > 0:
        net_batch_uncertainty = uncertainty.aleatoric_entropy(net_test.output_mask,
                                                              net_test.sigma_activations,
                                                              opts_test.aleatoric_sample_n)
    else:
        net_batch_uncertainty = \
            tf.constant(0, shape = [opts_test.batch_size, opts_test.shape_label[0], opts_test.shape_label[1]])
    # ###########################################################################
    # RUN UNET
    # ###########################################################################
    logging.debug("predicting, sampling %s times, batch_size %s" % (opts_test.n_samples, opts_test.batch_size))

    for b in range(opts_test.n_samples):
        try:
            logging.debug("run ...")
            batch_img, batch_label, batch_softmax, batch_prediction, batch_uncertainty \
                = sess.run(  [net_test.batch_img, net_test.batch_label,
                              net_batch_softmax, net_test.prediction, net_batch_uncertainty ])
        except tf.errors.OutOfRangeError:
            break
        logging.debug("... success")

        # reshape so that batch_size is merged into x dimension (images are concatenated along x dim)
        #logging.debug('  uncertainty: %s %s' % (str(batch_uncertainty.shape), str(batch_uncertainty.dtype)))
        batch_uncertainty = batch_uncertainty[..., np.newaxis]
        r_batch_img = np.reshape(batch_img, [-1, batch_img.shape[2], batch_img.shape[3]])
        r_batch_label = np.reshape(batch_label, [-1, batch_label.shape[2], batch_label.shape[3]])
        r_batch_softmax = np.reshape(batch_softmax, [-1, batch_softmax.shape[2], batch_softmax.shape[3]])
        r_batch_prediction = np.reshape(batch_prediction, [-1, batch_prediction.shape[2]])
        r_batch_uncertainty = np.reshape(batch_uncertainty, [-1, batch_uncertainty.shape[2], batch_uncertainty.shape[3]])

        import scipy.io
        # matlab arrays
        scipy.io.savemat("%s/tile_%02d.mat" % (args.test_dir, b), mdict={
            'tile' : r_batch_img,
            'label' : r_batch_label,
            'pred' : r_batch_prediction,
            'softmax' : r_batch_softmax,
            'uncertainty' : r_batch_uncertainty
        } )

        logging.debug('writing tile-file: %s/tile_%s.mat' % (args.test_dir, b))
        logging.debug('  softmax_activations: %s %s' % (str(r_batch_softmax.shape), str(r_batch_softmax.dtype)))
        logging.debug('  prediction: %s %s' % (str(r_batch_prediction.shape), str(r_batch_prediction.dtype)))
        logging.debug('  img: %s %s' % (str(r_batch_img.shape), str(r_batch_img.dtype)))
        logging.debug('  label: %s %s' % (str(r_batch_label.shape), str(r_batch_label.dtype)))
        logging.debug('  uncertainty: %s %s' % (str(r_batch_uncertainty.shape), str(r_batch_uncertainty.dtype)))

        # summary
        out_img = np.concatenate((np.squeeze(img_util.to_rgb(r_batch_img)),
                                  np.squeeze(img_util.to_rgb(r_batch_label)),
                                  #np.squeeze(img_util.to_rgb(r_batch_softmax[..., 0, np.newaxis], normalize=True)),
                                  np.squeeze(img_util.to_rgb(r_batch_softmax[..., 1, np.newaxis], normalize=True)),
                                  np.squeeze(img_util.to_rgb(r_batch_prediction[..., np.newaxis])),
                                  np.squeeze(img_util.to_rgb(r_batch_uncertainty[..., np.newaxis]))
                                  ), axis=1)
        img_util.save_image(out_img, "%s/tile_%02d_summary.png" % (args.test_dir, b))

        # ###########################################################################
        # CLOSE NET
        # ###########################################################################


# test with sampling for uncertainty (only makes sense when resample_n != None and keep_prob != 1.0
def test_debug_sampling(sess, net_test):
    logging.info('#-----------------------------------------------#')
    logging.info('#        Starting Testing with sampling         #')
    logging.info('#-----------------------------------------------#')

    # load model for testing (if None provided, searches in train_dir, if not found doesn't load)
    trainer = SimpleTrainer(session=sess, train_dir=args.train_dir)
    chkpt_loaded = trainer.load_checkpoint(args.checkpoint)
    args.test_dir = filesys.find_or_create_test_dir(args.test_dir, args.train_dir)

    # add uncertainty op if supported (network trained with aleatoric loss)
    if opts_test.aleatoric_sample_n is not None and opts_test.aleatoric_sample_n > 0:
        # get uncertainty (entropy) and sampled, softmaxed output mask
        net_batch_uncertainty, net_batch_softmax = uncertainty.aleatoric_entropy(net_test.output_mask,
                                                              net_test.sigma_activations,
                                                              opts_test.aleatoric_sample_n)
        # create prediction from sampled, softmaxed output mask
        net_batch_prediction = tf.argmax(tf.nn.softmax(net_batch_softmax), axis=-1, output_type=tf.int32)
    else:
        # add softmax op, default net prediction and dummy uncertainty
        net_batch_softmax = tf.nn.softmax(net_test.output_mask)
        net_batch_prediction = net_test.prediction
        # for default net w/o aleatoric loss no uncertainty is defined. Can be generated with dropout (resample_n)
        net_batch_uncertainty = tf.constant(0, shape=list(net_batch_softmax.shape)[0:3])

    # ###########################################################################
    # RUN UNET
    # ###########################################################################
    logging.debug("predicting: n_samples %s, resample_n %s, batch_size %s" %
                  (str(opts_test.n_samples), str(opts_test.resample_n), str(opts_test.batch_size)))

    # create folder to store samples in
    if opts_test.resample_n is not None:
        sample_dir = args.test_dir + os.sep + 'samples'
        os.mkdir(sample_dir)

    for b in range(opts_test.n_samples):
        # GENERATE RESULTS
        # ----------------
        try:
            # standard run (or first run if resampling, to get batch_img and batch_label once)
            logging.debug("run ...")
            batch_img, batch_label, batch_softmax, batch_prediction, batch_uncertainty \
                = sess.run([net_test.batch_img, net_test.batch_label,
                            net_batch_softmax, net_batch_prediction, net_batch_uncertainty])

            # if resampling, create store to sample into
            if opts_test.resample_n is not None:
                r_batch_pred = np.reshape(batch_prediction, [-1, batch_prediction.shape[2]])
                # init prediction_sample store
                prediction_samples = np.zeros([opts_test.resample_n] + list(r_batch_pred.shape), dtype=np.uint8)
                # store prediction for averaging
                prediction_samples[0, ...] = r_batch_pred
                if opts_test.aleatoric_sample_n is not None:
                    r_batch_uncertainty = np.reshape(batch_uncertainty, [-1, batch_uncertainty.shape[2]])
                    # init prediction_sample store
                    uncertainty_samples = np.zeros([opts_test.aleatoric_sample_n] + list(r_batch_uncertainty.shape), dtype=np.float32)
                    # store uncertainty for averaging (comes as [batch_size x y])
                    uncertainty_samples[0, ...] = r_batch_uncertainty

                # start sampling (-1 because one run was already done)
                for s in range(1,opts_test.resample_n):
                    batch_softmax, batch_prediction, batch_uncertainty \
                        = sess.run([net_batch_softmax, net_test.prediction, net_batch_uncertainty])

                    # store prediction
                    r_batch_pred = np.reshape(batch_prediction, [-1, batch_prediction.shape[2]])
                    prediction_samples[s, ...] = r_batch_pred
                    # save sample images to sample folder
                    out_sample = img_util.to_rgb(prediction_samples[s, ...])
                    img_util.save_image(out_sample, "%s/sample_%s_%s_pred.png" % (sample_dir, b, s))

                    if opts_test.aleatoric_sample_n is not None:
                        # store uncertainty
                        r_batch_uncertainty = np.reshape(batch_uncertainty, [-1, batch_uncertainty.shape[2]])
                        uncertainty_samples[s, ...] = r_batch_uncertainty
                        # save sample images to sample folder
                        out_sample = img_util.to_rgb(uncertainty_samples[s, ...])
                        img_util.save_image(out_sample, "%s/sample_%s_%s_unc.png" % (sample_dir, b, s))

        except tf.errors.OutOfRangeError:
            break

        # PROCESS RESULTS
        # ---------------
        # reshape so that batch_size is merged into x dimension (images are concatenated along x dim)
        r_batch_img = np.reshape(batch_img, [-1, batch_img.shape[2], batch_img.shape[3]])
        r_batch_label = np.reshape(batch_label, [-1, batch_label.shape[2], batch_label.shape[3]])
        r_batch_softmax = np.reshape(batch_softmax, [-1, batch_softmax.shape[2], batch_softmax.shape[3]])

        # if resampling, create pred and uncertainty from samples
        if opts_test.resample_n is not None:
            # create mean of samples and save as r_batch_prediction
            logging.info('resampled pred (%s), averaging for pred' % (str(opts_test.resample_n)))
            r_batch_prediction = np.mean(prediction_samples, axis=0)
            #std_deviation = np.std(prediction_samples, axis=0)

            if opts_test.aleatoric_sample_n is not None:
                #uncertainty_samples = uncertainty_samples[..., np.newaxis]
                # create mean of samples and save as r_batch_uncertainty
                logging.info('calculating combined entropy from %s aleatoric samples' % (str(opts_test.aleatoric_sample_n)))
                # create
                r_batch_uncertainty = - np.sum(uncertainty_samples * np.nan_to_num(np.log(uncertainty_samples)), axis=0)
                #r_batch_uncertainty = r_batch_uncertainty
                r_batch_uncertainty /= np.max(r_batch_uncertainty)
            else:
                logging.info('calculating epistemic entropy from %s pred samples' % (str(opts_test.resample_n)))
                # compute epistemic uncertainty and overwrite (empty) network output uncertainty
                #TODO entropy with softmax? but which class?
                r_batch_uncertainty = calc.entropy_bin_array(prediction_samples)
        else:
            r_batch_prediction = np.reshape(batch_prediction, [-1, batch_prediction.shape[2]])
            # append axis for easier processing in MATLAB (same rank as softmax)
            batch_uncertainty = batch_uncertainty[..., np.newaxis]
            r_batch_uncertainty = np.reshape(batch_uncertainty,
                                             [-1, batch_uncertainty.shape[2], batch_uncertainty.shape[3]])

        # WRITE RESULTS
        # -------------
        logging.debug('writing tile-file: %s/tile_%s.mat' % (args.test_dir, b))
        logging.debug('  softmax_activations: %s %s' % (str(r_batch_softmax.shape), str(r_batch_softmax.dtype)))
        logging.debug('  prediction: %s %s' % (str(r_batch_prediction.shape), str(r_batch_prediction.dtype)))
        logging.debug('  img: %s %s' % (str(r_batch_img.shape), str(r_batch_img.dtype)))
        logging.debug('  label: %s %s' % (str(r_batch_label.shape), str(r_batch_label.dtype)))
        logging.debug('  uncertainty: %s %s' % (str(r_batch_uncertainty.shape), str(r_batch_uncertainty.dtype)))

        # write matlab arrays
        scipy.io.savemat("%s/tile_%02d.mat" % (args.test_dir, b), mdict={
            'tile' : r_batch_img,
            'label' : r_batch_label,
            'pred' : r_batch_prediction,
            'softmax' : r_batch_softmax,
            'uncertainty' : r_batch_uncertainty
        } )

        # summary
        out_img = np.concatenate((np.squeeze(img_util.to_rgb(r_batch_img)),
                                  np.squeeze(img_util.to_rgb(r_batch_label)),
                                  #np.squeeze(img_util.to_rgb(r_batch_softmax[..., 0, np.newaxis], normalize=True)),
                                  np.squeeze(img_util.to_rgb(r_batch_softmax[..., 1, np.newaxis], normalize=True)),
                                  np.squeeze(img_util.to_rgb(r_batch_prediction[..., np.newaxis])),
                                  np.squeeze(img_util.to_rgb(r_batch_uncertainty[..., np.newaxis]))
                                  ), axis=1)
        img_util.save_image(out_img, "%s/tile_%02d_summary.png" % (args.test_dir, b))

        # ###########################################################################
        # CLOSE NET
        # ###########################################################################



def test_metrics(sess, net_test):
    logging.info('#-----------------------------------------------#')
    logging.info('#               Starting Testing (metrics)      #')
    logging.info('#-----------------------------------------------#')

    # load model for testing (if None provided, searches in train_dir, if not found doesn't load)
    logging.info("Attempt restore with SimpleTrainer load from: %s" % args.checkpoint)
    # load model for continued training (if None provided, searches in train_dir, if not found doesn't load)
    trainer = SimpleTrainer(session=sess, train_dir=args.train_dir)
    chkpt_loaded = trainer.load_checkpoint(args.checkpoint)

    # init variables if no checkpoint was loaded
    if not chkpt_loaded: sess.run(tf.group(tf.global_variables_initializer()))
    logging.info("Loaded variables from checkpoint" if chkpt_loaded else "Randomly initialized (!) variables")

    # create test op and initialize associated variables
    test_op = net_test.test_op()
    tf_helpers.initialize_uninitialized(sess, vars=tf.global_variables())
    tf_helpers.initialize_uninitialized(sess, vars=tf.local_variables())

    # ###########################################################################
    # RUN UNET
    # ###########################################################################
    logging.debug("predicting, sampling %s times, batch_size %s" % (opts_test.n_samples, opts_test.batch_size))

    [c_accuracy, c_precision, c_recall,
     c_accuracy_per_class, c_mean_iou] = [(0, 0), (0, 0), (0, 0), 0, 0]

    [global_step] = sess.run([net_test.global_step])
    args.test_dir = filesys.find_or_create_test_dir(args.test_dir, args.train_dir, global_step=global_step)

    for b in range(opts_test.n_samples):
        try:
            test_op_results = sess.run(test_op)
        except tf.errors.OutOfRangeError:
            break

        [batch_img, batch_label, batch_weights,
         batch_activations, batch_softmax, batch_prediction,
         accuracy, precision, recall,
         accuracy_per_class, mean_iou] = test_op_results

        [c_accuracy, c_precision, c_recall, c_accuracy_per_class, c_mean_iou] = \
            [[sum(x) for x in zip(accuracy,c_accuracy)],
             [sum(x) for x in zip(precision, c_precision)],
             [sum(x) for x in zip(recall, c_recall)],
              c_accuracy_per_class + accuracy_per_class[0],
              c_mean_iou + mean_iou[0]]

        # out_img = np.squeeze(img_util.to_rgb(batch_activations))
        # img_util.save_image(out_img, "%s/img_%s_pred.png" % (args.test_dir, b))
        # logging.debug('\naccuracy: %s, prec: %s, rec: %s \naccuracy_per_class %s, \nmean_iou %s' %
        #               (str(accuracy), str(precision), str(recall),
        #                str(accuracy_per_class), str(mean_iou)))
        #logging.debug('batch_activations: %s %s' % (str(batch_activations.shape), str(batch_activations.dtype)))
        #logging.debug('batch_prediction: %s %s' % (str(batch_prediction.shape), str(batch_prediction.dtype)))
        #logging.debug('batch_img: %s %s' % (str(batch_img.shape), str(batch_img.dtype)))
        #logging.debug('batch_label: %s %s' % (str(batch_label.shape), str(batch_label.dtype)))

        # logging.debug('describe prediction_samples: ' + str(stats.describe(batch_activations)))
        # logging.debug('describe prediction_samples[0]: ' + str(stats.describe(prediction_samples[0])))
        # out_img = img_util.combine_img_prediction(batch_img, batch_label, batch_activations)

        r_batch_img = np.reshape(batch_img, [-1, batch_img.shape[2], batch_img.shape[3]])
        r_batch_label = np.reshape(batch_label, [-1, batch_label.shape[2], batch_label.shape[3]])
        r_batch_activations = np.reshape(batch_activations,
                                         [-1, batch_activations.shape[2], batch_activations.shape[3]])
        r_batch_prediction = np.reshape(batch_prediction, [-1, batch_prediction.shape[2]])

        # r_batch_softmax = calc.softmax(r_batch_activations, axis=-1) # slow
        argmax = np.argmax(r_batch_activations, axis=-1)  # just take direct max

        out_img = np.concatenate((np.squeeze(img_util.to_rgb(r_batch_img)),
                                  np.squeeze(img_util.to_rgb(r_batch_label)),
                                  np.squeeze(img_util.to_rgb(r_batch_activations[..., 0, np.newaxis], normalize=False)),
                                  np.squeeze(img_util.to_rgb(r_batch_activations[..., 1, np.newaxis], normalize=False)),
                                  np.squeeze(img_util.to_rgb(argmax[..., np.newaxis])),
                                  np.squeeze(img_util.to_rgb(r_batch_prediction[..., np.newaxis]))
                                  ), axis=1)

        img_util.save_image(out_img, "%s/img_%s.png" % (args.test_dir, b))

        # ###########################################################################
        # CLOSE NET
        # ###########################################################################

    c_accuracy = tuple(x / opts_test.n_samples for x in c_accuracy)
    c_precision = tuple(x / opts_test.n_samples for x in c_precision)
    c_recall = tuple(x / opts_test.n_samples for x in c_recall)
    c_accuracy_per_class = c_accuracy_per_class / opts_test.n_samples
    c_mean_iou = c_mean_iou / opts_test.n_samples
    logging.debug('\naccuracy: %s, prec: %s, rec: %s \naccuracy_per_class %s, \nmean_iou %s' %
                          (str(c_accuracy), str(c_precision), str(c_recall),
                           str(c_accuracy_per_class), str(c_mean_iou)))


def TEST(): pass # dummy function for PyCharm IDE
if opts.test:
    logging.info('####################################################################')
    logging.info('#                            TESTING                               #')
    logging.info('####################################################################')

    # set checkpoint path from opts if set in there not given per command line (CL) argument
    if args.checkpoint is None and opts_test.global_step is not None:
        args.checkpoint = args.train_dir + '/checkpoints/snapshot-' + str(opts_test.global_step)

    args.test_dir = filesys.find_or_create_test_dir(args.test_dir, args.train_dir, opts=opts_test)

    with tf_debug.LocalCLIDebugWrapperSession(tf.Session(config=opts.tf_config)) if opts.tfdbg \
            else tf.Session(config=opts.tf_config) as sess:

        # create network graph with data layer
        net = model.UNet(is_training=False, keep_prob=opts_test.keep_prob,
                         n_contracting_blocks=opts_test.n_contracting_blocks,
                         n_start_features=opts_test.n_start_features,
                         norm_fn=opts_test.norm_fn, normalizer_params=opts_test.norm_fn_params,
                         aleatoric_sample_n=opts_test.aleatoric_sample_n,
                         copy_script_dir=args.code_copy_dir, debug=opts.debug,
                         opts_main=opts_test,
                         sess=sess, train_dir=args.train_dir)

        # for hdf5 and feed_dict layers no coordinators need to be initialized
        # different when using tfrecords
        if opts.debug:
            test_debug_sampling(sess, net)
        else:
            if opts_test.resample_n is not None:
                test_sampling(sess, net)
            else:
                test_core(sess, net)


    logging.info('#-X---------------------------------------------#')
    logging.info('#                Finish Testing                 #')
    logging.info('#-----------------------------------------------#')






# ######################################################################################################################
# ######################################################################################################################
# DEBUG
# --------
def __________________________DEBUG_____________________________(): pass  # dummy function for PyCharm IDE
# reset graph so that variables don't have to be reused (they will be restored from checkpoint)
if opts.train: tf.reset_default_graph()

opts.batch_size = 5

# core code for training
def DEBUG_core(sess):
    logging.info('#-----------------------------------------------#')
    logging.info('#                Start Debugging                #')
    logging.info('#-----------------------------------------------#')

    args.test_dir = filesys.find_or_create_test_dir(args.test_dir, args.train_dir, opts=opts_test)

    batch_img, batch_label, batch_weights = data_layers.data_HDF5(opts_train.dataset,
                                                                  opts_train.shape_img, opts_train.shape_label, opts_train.shape_weights,
                                                                  shuffle=False, batch_size=opts.batch_size,
                                                                  prefetch_threads=12, prefetch_n=40,
                                                                  resample_n=40,
                                                                  augment=True)

    resize = opts_train.resize
    if opts_train.resize is not None:
        if opts_train.resize_method == "scale":
            batch_img = tf.image.resize_images(batch_img, resize)
            batch_label = tf.image.resize_images(batch_label, resize)
            batch_label = tf.cast(batch_label, tf.uint8)  # is changed by resize
            batch_weights = tf.image.resize_images(batch_weights, resize)
        elif opts_train.resize_method == "center_crop":
            batch_img = tf.map_fn(lambda img: tf.image.central_crop(img, 0.5),
                                       batch_img, parallel_iterations=8, name="center_crop")
            batch_label = tf.map_fn(lambda img: tf.image.central_crop(img, 0.5),
                                         batch_label, parallel_iterations=8, name="center_crop")
            batch_weights = tf.map_fn(lambda img: tf.image.central_crop(img, 0.5),
                                           batch_weights, parallel_iterations=8, name="center_crop")
        else:
            random_seed = 42  # tf.random_uniform(1, minval=0, maxval=65536, dtype=tf.int16)
            batch_img = tf.random_crop(batch_img,
                                            [batch_img.get_shape().as_list()[0], resize[0], resize[1],
                                             batch_img.get_shape().as_list()[3]], seed=random_seed)
            batch_label = tf.random_crop(batch_label,
                                              [batch_label.get_shape().as_list()[0], resize[0], resize[1],
                                               batch_label.get_shape().as_list()[3]], seed=random_seed)
            batch_weights = tf.random_crop(batch_weights,
                                                [batch_weights.get_shape().as_list()[0], resize[0], resize[1],
                                                 batch_weights.get_shape().as_list()[3]], seed=random_seed)

    for bb in range(opts_test.n_samples):
        r_batch_img = []
        for b in range(8):
            start = timer()
            e_batch_img, e_batch_label, e_batch_weights = sess.run([batch_img, batch_label, batch_weights])
            end = timer()

            print("got batch in %.4f s : img %s %s" % ((end - start), str(e_batch_img.shape), str(e_batch_img.dtype)))

            r_batch_img.append(np.reshape(e_batch_img, [-1, e_batch_img.shape[2], e_batch_img.shape[3]]))

        print("stitching and creating file")
        out_img = np.concatenate([img_util.to_rgb(batch) for batch in r_batch_img], axis=1)
        img_util.save_image(out_img, "%s/img_aug_%s.jpg" % (args.test_dir, str(bb)))


# TODO: Remove debugging code
if opts.debug and False:  # temporarily disabled
    logging.info('####################################################################')
    logging.info('#                           DEBUGGING                              #')
    logging.info('####################################################################')

    with tf.Session(config=opts.tf_config) as sess:
        DEBUG_core(sess)

    logging.info('#-X---------------------------------------------#')
    logging.info('#               Finish Debugging                #')
    logging.info('#-----------------------------------------------#')

logging.info('\n\n ... done :)')
